{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "impossible-seventh",
   "metadata": {},
   "source": [
    "# env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "designed-teach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "import os, sys, logging, json, pandas as pd, numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import cpu_count\n",
    "print(cpu_count())\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "PROJECT = \"yaa\"\n",
    "                                          \n",
    "#WORKDIR = os.path.abspath(f\"{PATH TO CODE}/{PROJECT}\")\n",
    "WORKDIR = os.path.abspath(\"./\")\n",
    "os.chdir(WORKDIR)\n",
    "\n",
    "OUTPUTDIR=os.path.join(WORKDIR, \"data\")\n",
    "DATADIR = os.path.join(WORKDIR, 'data')\n",
    "NUM = int(1e16)\n",
    "\n",
    "BATCHSIZE = 512\n",
    "\n",
    "sys.path.insert(0, WORKDIR)\n",
    "os.environ['PYTHONPATH']=WORKDIR\n",
    "\n",
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "import util\n",
    "from importlib import reload\n",
    "reload(util)\n",
    "args = util.parser.parse_args([])\n",
    "util.set_logger(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e948b7ea-1654-46f7-93e9-126c96ad451a",
   "metadata": {},
   "source": [
    "# gen rewrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d05f8d-43d4-4e2b-a410-5f94cddfa1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelid=\"Qwen/Qwen2-7B-Instruct\"\n",
    "for i in range(10):\n",
    "    GENSEED=100+i\n",
    "    !TRANSFORMERS_OFFLINE=1 python gen_data.py -m gen   -modelid \"{modelid}\" -output_dir ../data/gen/qw2_7b_{GENSEED} -n_sample 1 -gen_seed {GENSEED}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51256941-9863-45e3-b898-49c990d40601",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelid=\"Qwen/Qwen2.5-7B-Instruct\"\n",
    "for i in range(10):\n",
    "    GENSEED=200+i\n",
    "    !TRANSFORMERS_OFFLINE=1 python gen_data.py -m gen   -modelid \"{modelid}\" -output_dir ../data/gen/qw2d5_7b_{GENSEED} -n_sample 1 -gen_seed {GENSEED}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b0be26-5158-4079-a72d-8bd555e94513",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelid=\"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "for i in range(10):\n",
    "    GENSEED=300+i\n",
    "    !TRANSFORMERS_OFFLINE=1 python gen_data.py -m gen   -modelid \"{modelid}\" -output_dir ../data/gen/mistral0d3_7b_{GENSEED} -n_sample 1 -gen_seed {GENSEED}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d97aaef-71d3-44a4-9ca1-681df31921a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelid=\"google/gemma-2-9b-it\"\n",
    "for i in range(10):\n",
    "    GENSEED=3000+i\n",
    "    !TRANSFORMERS_OFFLINE=1 python gen_data.py -m gen   -modelid \"{modelid}\" -output_dir ../data/gen/gemma2_9b_{GENSEED} -n_sample 1 -gen_seed {GENSEED}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a0aed0-2c8b-4b5c-a007-8873624349da",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelid=\"unsloth/llama-3-8b-Instruct\"\n",
    "for i in range(0, 10):\n",
    "    GENSEED=1000+i\n",
    "    !TRANSFORMERS_OFFLINE=1 python gen_data.py -m gen   -modelid \"{modelid}\" -output_dir ../data/gen/llama3_8b_{GENSEED} -n_sample 1 -gen_seed {GENSEED}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5ea6a6-04c8-4c1e-a125-9a9813a29258",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelid=\"unsloth/Meta-Llama-3.1-8B-Instruct\"\n",
    "for i in range(10):\n",
    "    GENSEED=2000+i\n",
    "    !TRANSFORMERS_OFFLINE=1 python gen_data.py -m gen   -modelid \"{modelid}\" -output_dir ../data/gen/llama3d1_8b_{GENSEED} -n_sample 1 -gen_seed {GENSEED}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23699e3e-28d1-4c48-970f-20745a9fab6e",
   "metadata": {},
   "source": [
    "# stage1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ca1f10-5a8e-4f7c-a44d-22d0982c65db",
   "metadata": {},
   "source": [
    "## AR_qw2d5_3b_d04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f0e6d0-b1ed-4e26-876e-cad94b4b6ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"AR_qw2d5_3b_d04\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"unsloth/Qwen2.5-3B-Instruct\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=212345\n",
    "DATASEED=SEED\n",
    "TRAINCOLS=\" \".join(util.all_labels)\n",
    "KN=4\n",
    "KFIDS=\"0\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 0 \\\n",
    "-epochs 2   -max_seq_len 8192  -do_train  -dataloader_num_workers 4 -es 1 -verbose 320 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 2e-4 -warmup_ratio 0.01 -weight_decay 0.01 -bs 1 -gas 16 -vbs 1 -torch_dtype bfloat16 -use_bf16 -train_cols {TRAINCOLS}  \\\n",
    "-use_unsloth -use_lora -lora_dropout 0.05 -lora_alpha 16 -lora_rank 32 -lora_modules q_proj o_proj gate_proj up_proj down_proj k_proj v_proj lm_head -gradient_checkpointing \\\n",
    "-use_ppt2 -aug_order 0.5 \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 1  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval \\\n",
    "2>&1 | tee -a \"{LOGFILE}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745afe52-0b30-41de-9681-cdf882433c33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1e55be-fadf-4d2a-815b-57c65e7edf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"AR_qw2d5_3b_d04\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"unsloth/Qwen2.5-3B-Instruct\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=212345\n",
    "DATASEED=SEED\n",
    "TRAINCOLS=\" \".join(util.all_labels)\n",
    "KN=4\n",
    "KFIDS=\"1 2 3\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 0 \\\n",
    "-epochs 2   -max_seq_len 8192  -do_train  -dataloader_num_workers 4 -es 1 -verbose 320 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 2e-4 -warmup_ratio 0.01 -weight_decay 0.01 -bs 1 -gas 16 -vbs 1 -torch_dtype bfloat16 -use_bf16 -train_cols {TRAINCOLS}  \\\n",
    "-use_unsloth -use_lora -lora_dropout 0.05 -lora_alpha 16 -lora_rank 32 -lora_modules q_proj o_proj gate_proj up_proj down_proj k_proj v_proj lm_head -gradient_checkpointing \\\n",
    "-use_ppt2 -aug_order 0.5 \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"0 1 2 3\" -data_type train  -ds {DS} -vbs 1  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval \\\n",
    "2>&1 | tee -a \"{LOGFILE}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d4efd7-ccf0-4890-8e7f-fd598a887afa",
   "metadata": {},
   "source": [
    "## AR_llama3d2_1b_d37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42eeba5a-d0e2-48df-8e08-369b75a874c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"AR_llama3d2_1b_d37\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"unsloth/Llama-3.2-1B-Instruct\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=543509\n",
    "DATASEED=SEED\n",
    "TRAINCOLS=\" \".join(util.all_labels)\n",
    "KN=4\n",
    "KFIDS=\"0\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 0 \\\n",
    "-epochs 2   -max_seq_len 8192  -do_train  -dataloader_num_workers 4 -es 1 -verbose 320 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 2e-4 -warmup_ratio 0.01 -weight_decay 0.01 -bs 1 -gas 16 -vbs 1 -torch_dtype bfloat16 -use_bf16 -train_cols {TRAINCOLS}  \\\n",
    "-use_unsloth -use_lora -lora_dropout 0.05 -lora_alpha 16 -lora_rank 32 -lora_modules q_proj o_proj gate_proj up_proj down_proj k_proj v_proj lm_head  \\\n",
    "-use_ppt2 -aug_order 0.5 \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 1  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval \\\n",
    "2>&1 | tee -a \"{LOGFILE}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47f7450-4765-4596-8dd9-631920d67ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"AR_llama3d2_1b_d37\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"unsloth/Llama-3.2-1B-Instruct\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=543509\n",
    "DATASEED=SEED\n",
    "TRAINCOLS=\" \".join(util.all_labels)\n",
    "KN=4\n",
    "KFIDS=\"1 2 3\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 0 \\\n",
    "-epochs 2   -max_seq_len 8192  -do_train  -dataloader_num_workers 4 -es 1 -verbose 320 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 2e-4 -warmup_ratio 0.01 -weight_decay 0.01 -bs 1 -gas 16 -vbs 1 -torch_dtype bfloat16 -use_bf16 -train_cols {TRAINCOLS}  \\\n",
    "-use_unsloth -use_lora -lora_dropout 0.05 -lora_alpha 16 -lora_rank 32 -lora_modules q_proj o_proj gate_proj up_proj down_proj k_proj v_proj lm_head  \\\n",
    "-use_ppt2 -aug_order 0.5 \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"0 1 2 3\" -data_type train  -ds {DS} -vbs 1  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval \\\n",
    "2>&1 | tee -a \"{LOGFILE}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e20e1b-24ef-4b94-8a2c-0e483992a277",
   "metadata": {},
   "source": [
    "## AR_llama3d2_3b_d03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103a5080-cd4e-4f88-a7f5-6fd71704ef41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"AR_llama3d2_3b_d03\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"unsloth/Llama-3.2-3B-Instruct\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=232567\n",
    "DATASEED=SEED\n",
    "TRAINCOLS=\" \".join(util.all_labels)\n",
    "KN=4\n",
    "KFIDS=\"0\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 0 \\\n",
    "-epochs 2   -max_seq_len 8192  -do_train  -dataloader_num_workers 4 -es 1 -verbose 320 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 2e-4 -warmup_ratio 0.01 -weight_decay 0.01 -bs 1 -gas 16 -vbs 1 -torch_dtype bfloat16 -use_bf16 -train_cols {TRAINCOLS}  \\\n",
    "-use_unsloth -use_lora -lora_dropout 0.05 -lora_alpha 16 -lora_rank 32 -lora_modules q_proj o_proj gate_proj up_proj down_proj k_proj v_proj lm_head  \\\n",
    "-use_ppt2 -aug_order 0.5 \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 1  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval \\\n",
    "2>&1 | tee -a \"{LOGFILE}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f427cf19-8636-4f97-b4ea-3a07b64ce25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"AR_llama3d2_3b_d03\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"unsloth/Llama-3.2-3B-Instruct\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=232567\n",
    "DATASEED=SEED\n",
    "TRAINCOLS=\" \".join(util.all_labels)\n",
    "KN=4\n",
    "KFIDS=\"1\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 0 \\\n",
    "-epochs 2   -max_seq_len 8192  -do_train  -dataloader_num_workers 4 -es 1 -verbose 320 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 2e-4 -warmup_ratio 0.01 -weight_decay 0.01 -bs 1 -gas 16 -vbs 1 -torch_dtype bfloat16 -use_bf16 -train_cols {TRAINCOLS}  \\\n",
    "-use_unsloth -use_lora -lora_dropout 0.05 -lora_alpha 16 -lora_rank 32 -lora_modules q_proj o_proj gate_proj up_proj down_proj k_proj v_proj lm_head  \\\n",
    "-use_ppt2 -aug_order 0.5 \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 1  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval \\\n",
    "2>&1 | tee -a \"{LOGFILE}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620d868e-f657-43a4-897b-9271557d282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"AR_llama3d2_3b_d03\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"unsloth/Llama-3.2-3B-Instruct\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=232567\n",
    "DATASEED=SEED\n",
    "TRAINCOLS=\" \".join(util.all_labels)\n",
    "KN=4\n",
    "KFIDS=\"2\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 0 \\\n",
    "-epochs 2   -max_seq_len 8192  -do_train  -dataloader_num_workers 4 -es 1 -verbose 320 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 2e-4 -warmup_ratio 0.01 -weight_decay 0.01 -bs 1 -gas 16 -vbs 1 -torch_dtype bfloat16 -use_bf16 -train_cols {TRAINCOLS}  \\\n",
    "-use_unsloth -use_lora -lora_dropout 0.05 -lora_alpha 16 -lora_rank 32 -lora_modules q_proj o_proj gate_proj up_proj down_proj k_proj v_proj lm_head  \\\n",
    "-use_ppt2 -aug_order 0.5 \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 1  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval \\\n",
    "2>&1 | tee -a \"{LOGFILE}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8271c17-608d-4f24-a5c6-144eef1410b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"AR_llama3d2_3b_d03\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"unsloth/Llama-3.2-3B-Instruct\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=232567\n",
    "DATASEED=SEED\n",
    "TRAINCOLS=\" \".join(util.all_labels)\n",
    "KN=4\n",
    "KFIDS=\"3\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 0 \\\n",
    "-epochs 2   -max_seq_len 8192  -do_train  -dataloader_num_workers 4 -es 1 -verbose 320 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 2e-4 -warmup_ratio 0.01 -weight_decay 0.01 -bs 1 -gas 16 -vbs 1 -torch_dtype bfloat16 -use_bf16 -train_cols {TRAINCOLS}  \\\n",
    "-use_unsloth -use_lora -lora_dropout 0.05 -lora_alpha 16 -lora_rank 32 -lora_modules q_proj o_proj gate_proj up_proj down_proj k_proj v_proj lm_head  \\\n",
    "-use_ppt2 -aug_order 0.5 \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"0 1 2 3\" -data_type train  -ds {DS} -vbs 1  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval \\\n",
    "2>&1 | tee -a \"{LOGFILE}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0352a200-bdcd-4cf7-b2d0-ca32d811ffaa",
   "metadata": {},
   "source": [
    "## AR_gemma2_2b_d02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96064f95-8045-4d25-b775-a8788739b846",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"AR_gemma2_2b_d02\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"unsloth/gemma-2-2b-it\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=905687\n",
    "DATASEED=SEED\n",
    "TRAINCOLS=\" \".join(util.all_labels)\n",
    "KN=4\n",
    "KFIDS=\"0\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 0 \\\n",
    "-epochs 2   -max_seq_len 8192  -do_train  -dataloader_num_workers 4 -es 1 -verbose 320 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 2e-4 -warmup_ratio 0.01 -weight_decay 0.01 -bs 1 -gas 16 -vbs 1 -torch_dtype bfloat16 -use_bf16 -train_cols {TRAINCOLS}  \\\n",
    "-use_unsloth -use_lora -lora_dropout 0.05 -lora_alpha 16 -lora_rank 32 -lora_modules q_proj o_proj gate_proj up_proj down_proj k_proj v_proj lm_head -gradient_checkpointing \\\n",
    "-use_ppt2 -aug_order 0.5 \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 1  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval \\\n",
    "2>&1 | tee -a \"{LOGFILE}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf2553f-193d-4ea4-8010-bfb1c29a7d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"AR_gemma2_2b_d02\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"unsloth/gemma-2-2b-it\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=905687\n",
    "DATASEED=SEED\n",
    "TRAINCOLS=\" \".join(util.all_labels)\n",
    "KN=4\n",
    "KFIDS=\"1\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 0 \\\n",
    "-epochs 2   -max_seq_len 8192  -do_train  -dataloader_num_workers 4 -es 1 -verbose 320 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 2e-4 -warmup_ratio 0.01 -weight_decay 0.01 -bs 1 -gas 16 -vbs 1 -torch_dtype bfloat16 -use_bf16 -train_cols {TRAINCOLS}  \\\n",
    "-use_unsloth -use_lora -lora_dropout 0.05 -lora_alpha 16 -lora_rank 32 -lora_modules q_proj o_proj gate_proj up_proj down_proj k_proj v_proj lm_head -gradient_checkpointing \\\n",
    "-use_ppt2 -aug_order 0.5 \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 1  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval \\\n",
    "2>&1 | tee -a \"{LOGFILE}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d27b69-1404-4206-9ce0-470b59429aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"AR_gemma2_2b_d02\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"unsloth/gemma-2-2b-it\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=905687\n",
    "DATASEED=SEED\n",
    "TRAINCOLS=\" \".join(util.all_labels)\n",
    "KN=4\n",
    "KFIDS=\"2\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 0 \\\n",
    "-epochs 2   -max_seq_len 8192  -do_train  -dataloader_num_workers 4 -es 1 -verbose 320 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 2e-4 -warmup_ratio 0.01 -weight_decay 0.01 -bs 1 -gas 16 -vbs 1 -torch_dtype bfloat16 -use_bf16 -train_cols {TRAINCOLS}  \\\n",
    "-use_unsloth -use_lora -lora_dropout 0.05 -lora_alpha 16 -lora_rank 32 -lora_modules q_proj o_proj gate_proj up_proj down_proj k_proj v_proj lm_head -gradient_checkpointing \\\n",
    "-use_ppt2 -aug_order 0.5 \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 1  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval \\\n",
    "2>&1 | tee -a \"{LOGFILE}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3e6c2a-1421-4032-89b5-e8f297e03106",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"AR_gemma2_2b_d02\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"unsloth/gemma-2-2b-it\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=905687\n",
    "DATASEED=SEED\n",
    "TRAINCOLS=\" \".join(util.all_labels)\n",
    "KN=4\n",
    "KFIDS=\"3\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 0 \\\n",
    "-epochs 2   -max_seq_len 8192  -do_train  -dataloader_num_workers 4 -es 1 -verbose 320 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 2e-4 -warmup_ratio 0.01 -weight_decay 0.01 -bs 1 -gas 16 -vbs 1 -torch_dtype bfloat16 -use_bf16 -train_cols {TRAINCOLS}  \\\n",
    "-use_unsloth -use_lora -lora_dropout 0.05 -lora_alpha 16 -lora_rank 32 -lora_modules q_proj o_proj gate_proj up_proj down_proj k_proj v_proj lm_head -gradient_checkpointing \\\n",
    "-use_ppt2 -aug_order 0.5 \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 1  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval \\\n",
    "2>&1 | tee -a \"{LOGFILE}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95719ff-8c39-45f6-82ea-8f227787e668",
   "metadata": {},
   "source": [
    "## SFT_debv2xxl_d36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d25a1d-aced-46e5-bcf4-cad40494eb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"SFT_debv2xxl_d36\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"microsoft/deberta-v2-xxlarge\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=345342\n",
    "DATASEED=SEED\n",
    "KN=4\n",
    "KFIDS=0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids {KFIDS} -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 3 \\\n",
    "-epochs  15  -max_seq_len 8192  -do_train -do_eval -dataloader_num_workers 4 -es 3 -verbose 32 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 5e-5 -warmup_ratio 0.1 -weight_decay 0.01 -bs 1 -gas 32 -vbs 2 -torch_dtype bfloat16 -use_bf16 -is_classify  -use_full -gradient_checkpointing -avg_pool \\\n",
    "-w_bi 0.33333 -w_lt 0.33333 -w_wt 0.33333  -aug_mix 0 -aug_lower 0 -aug_text 0.4 -bi_rdrop 2  \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 2  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8437752c-96c1-4e7f-a706-0f7c74573765",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"SFT_debv2xxl_d36\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"microsoft/deberta-v2-xxlarge\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=345342\n",
    "DATASEED=SEED\n",
    "KN=4\n",
    "KFIDS=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids {KFIDS} -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 3 \\\n",
    "-epochs  15  -max_seq_len 8192  -do_train -do_eval -dataloader_num_workers 4 -es 3 -verbose 32 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 5e-5 -warmup_ratio 0.1 -weight_decay 0.01 -bs 1 -gas 32 -vbs 2 -torch_dtype bfloat16 -use_bf16 -is_classify  -use_full -gradient_checkpointing -avg_pool \\\n",
    "-w_bi 0.33333 -w_lt 0.33333 -w_wt 0.33333  -aug_mix 0 -aug_lower 0 -aug_text 0.4 -bi_rdrop 2  \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 2  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779cbcd5-f8e5-4019-890e-bf46f5a6b8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"SFT_debv2xxl_d36\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"microsoft/deberta-v2-xxlarge\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=345342\n",
    "DATASEED=SEED\n",
    "KN=4\n",
    "KFIDS=\"2\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 3 \\\n",
    "-epochs  15  -max_seq_len 8192  -do_train -do_eval -dataloader_num_workers 4 -es 3 -verbose 32 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 5e-5 -warmup_ratio 0.1 -weight_decay 0.01 -bs 1 -gas 32 -vbs 2 -torch_dtype bfloat16 -use_bf16 -is_classify  -use_full -gradient_checkpointing -avg_pool \\\n",
    "-w_bi 0.33333 -w_lt 0.33333 -w_wt 0.33333  -aug_mix 0 -aug_lower 0 -aug_text 0.4 -bi_rdrop 2  \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"0 1 2 3\" -data_type train  -ds {DS} -vbs 2  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c80df7d-270a-479e-a3d3-57486be37b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"SFT_debv2xxl_d36\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"microsoft/deberta-v2-xxlarge\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=345342\n",
    "DATASEED=SEED\n",
    "KN=4\n",
    "KFIDS=\"3\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 3 \\\n",
    "-epochs  15  -max_seq_len 8192  -do_train -do_eval -dataloader_num_workers 4 -es 3 -verbose 32 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 5e-5 -warmup_ratio 0.05 -weight_decay 0.01 -bs 1 -gas 32 -vbs 2 -torch_dtype bfloat16 -use_bf16 -is_classify  -use_full -gradient_checkpointing -avg_pool \\\n",
    "-w_bi 0.33333 -w_lt 0.33333 -w_wt 0.33333  -aug_mix 0 -aug_lower 0 -aug_text 0.4 -bi_rdrop 2  \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 2  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571848bf-8838-48c7-b185-e38b0bdae6e7",
   "metadata": {},
   "source": [
    "## SFT_debv2xl_d120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb366c7-214c-4e7f-86a1-32c25bf41aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"SFT_debv2xl_d120\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"microsoft/deberta-v2-xlarge\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=19627\n",
    "DATASEED=SEED\n",
    "KN=4\n",
    "KFIDS=\"0\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 3 \\\n",
    "-epochs 15   -max_seq_len 8192  -do_train -do_eval -dataloader_num_workers 4 -es 3 -verbose 32 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 5e-5 -warmup_ratio 0.1 -weight_decay 0.01 -bs 1 -gas 16 -vbs 2 -torch_dtype bfloat16 -use_bf16 -is_classify  -use_full -gradient_checkpointing \\\n",
    "-w_bi 0.33333 -w_lt 0.33333 -w_wt 0.33333  -aug_order 0 -aug_missing 0 -aug_mix 0 -aug_text 0.4 -avg_pool -bi_rdrop 3 \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 2  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcbd8bb-01a5-47dc-a450-c4f82e9996c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"SFT_debv2xl_d120\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"microsoft/deberta-v2-xlarge\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=19627\n",
    "DATASEED=SEED\n",
    "KN=4\n",
    "KFIDS=\"1\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 3 \\\n",
    "-epochs 15   -max_seq_len 8192  -do_train -do_eval -dataloader_num_workers 4 -es 3 -verbose 32 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 5e-5 -warmup_ratio 0.1 -weight_decay 0.01 -bs 1 -gas 16 -vbs 2 -torch_dtype bfloat16 -use_bf16 -is_classify  -use_full -gradient_checkpointing \\\n",
    "-w_bi 0.33333 -w_lt 0.33333 -w_wt 0.33333  -aug_order 0 -aug_missing 0 -aug_mix 0 -aug_text 0.4 -avg_pool -bi_rdrop 3 \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 2  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a08c9fd-452b-420e-bf2e-0e1d13b81b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"SFT_debv2xl_d120\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"microsoft/deberta-v2-xlarge\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=19627\n",
    "DATASEED=SEED\n",
    "KN=4\n",
    "KFIDS=\"2\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 3 \\\n",
    "-epochs 15   -max_seq_len 8192  -do_train -do_eval -dataloader_num_workers 4 -es 3 -verbose 32 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 5e-5 -warmup_ratio 0.1 -weight_decay 0.01 -bs 1 -gas 16 -vbs 2 -torch_dtype bfloat16 -use_bf16 -is_classify  -use_full -gradient_checkpointing \\\n",
    "-w_bi 0.33333 -w_lt 0.33333 -w_wt 0.33333  -aug_order 0 -aug_missing 0 -aug_mix 0 -aug_text 0.4 -avg_pool -bi_rdrop 3 \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 2  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e935de20-16d8-4ea9-8cf0-30abc851c94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"SFT_debv2xl_d120\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"microsoft/deberta-v2-xlarge\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=19627\n",
    "DATASEED=SEED\n",
    "KN=4\n",
    "KFIDS=\"3\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 3 \\\n",
    "-epochs 15   -max_seq_len 8192  -do_train -do_eval -dataloader_num_workers 4 -es 3 -verbose 32 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 5e-5 -warmup_ratio 0.1 -weight_decay 0.01 -bs 1 -gas 16 -vbs 2 -torch_dtype bfloat16 -use_bf16 -is_classify  -use_full -gradient_checkpointing \\\n",
    "-w_bi 0.33333 -w_lt 0.33333 -w_wt 0.33333  -aug_order 0 -aug_missing 0 -aug_mix 0 -aug_text 0.4 -avg_pool -bi_rdrop 3 \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 2  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ae847c-1dd5-49f3-9f19-831005c61b03",
   "metadata": {},
   "source": [
    "## SPLIT_debv2xl_d10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8af796-07d2-4bfd-aee7-98d857270155",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"SPLIT_debv2xl_d10\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"microsoft/deberta-v2-xlarge\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=985034\n",
    "DATASEED=SEED\n",
    "KFIDS=0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn 4  -kfids {KFIDS} -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 3 \\\n",
    "-epochs 15   -max_seq_len 8192  -do_train -do_eval -dataloader_num_workers 4 -es 3 -verbose 32 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 5e-5 -warmup_ratio 0.1 -weight_decay 0.01 -bs 1 -gas 16 -vbs 2 -torch_dtype bfloat16 -use_bf16 -is_classify -is_split -use_full -gradient_checkpointing \\\n",
    "-w_bi 0.33333 -w_lt 0.33333 -w_wt 0.33333  -aug_order 0 -aug_missing 0 -aug_mix 0 -aug_text 0.1 -avg_pool -bi_rdrop 3  \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn 4 -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 2  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac813746-682b-49da-bd9e-d2743176dfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"SPLIT_debv2xl_d10\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"microsoft/deberta-v2-xlarge\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=985034\n",
    "DATASEED=SEED\n",
    "KFIDS=\"1\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn 4  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 3 \\\n",
    "-epochs 15   -max_seq_len 8192  -do_train -do_eval -dataloader_num_workers 4 -es 3 -verbose 32 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 5e-5 -warmup_ratio 0.1 -weight_decay 0.01 -bs 1 -gas 16 -vbs 2 -torch_dtype bfloat16 -use_bf16 -is_classify -is_split -use_full -gradient_checkpointing \\\n",
    "-w_bi 0.33333 -w_lt 0.33333 -w_wt 0.33333  -aug_order 0 -aug_missing 0 -aug_mix 0 -aug_text 0.1 -avg_pool -bi_rdrop 3  \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn 4 -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 2  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7e9e38-f3cd-4c0b-9dec-72782cac9337",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"SPLIT_debv2xl_d10\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"microsoft/deberta-v2-xlarge\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=985034\n",
    "DATASEED=SEED\n",
    "KFIDS=\"2\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn 4  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 3 \\\n",
    "-epochs 15   -max_seq_len 8192  -do_train -do_eval -dataloader_num_workers 4 -es 3 -verbose 32 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 5e-5 -warmup_ratio 0.1 -weight_decay 0.01 -bs 1 -gas 16 -vbs 2 -torch_dtype bfloat16 -use_bf16 -is_classify -is_split -use_full -gradient_checkpointing \\\n",
    "-w_bi 0.33333 -w_lt 0.33333 -w_wt 0.33333  -aug_order 0 -aug_missing 0 -aug_mix 0 -aug_text 0.1 -avg_pool -bi_rdrop 3  \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn 4 -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 2  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d66ca2-3fa5-4b9f-99c0-b4238e0bddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"SPLIT_debv2xl_d10\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"microsoft/deberta-v2-xlarge\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=985034\n",
    "DATASEED=SEED\n",
    "KFIDS=\"3\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn 4  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 3 \\\n",
    "-epochs 15   -max_seq_len 8192  -do_train -do_eval -dataloader_num_workers 4 -es 3 -verbose 32 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 5e-5 -warmup_ratio 0.1 -weight_decay 0.01 -bs 1 -gas 16 -vbs 2 -torch_dtype bfloat16 -use_bf16 -is_classify -is_split -use_full -gradient_checkpointing \\\n",
    "-w_bi 0.33333 -w_lt 0.33333 -w_wt 0.33333  -aug_order 0 -aug_missing 0 -aug_mix 0 -aug_text 0.1 -avg_pool -bi_rdrop 3  \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn 4 -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 2  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23d1e63-d429-405e-8d29-a5370764f30b",
   "metadata": {},
   "source": [
    "# gen semi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76e94cc-628c-4854-bd28-780d5e3d3f13",
   "metadata": {},
   "source": [
    "## gen data  (please run the cell sequentially, the program will exclude already used examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab9f394-9d2e-4db2-a61d-6a25862c9431",
   "metadata": {},
   "source": [
    "### gen2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865415bb-a607-4980-832e-2ccaa6b77fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "modelid=\"unsloth/Meta-Llama-3.1-8B-Instruct\"\n",
    "!TRANSFORMERS_OFFLINE=1 python gen_data.py -m gen2   -modelid \"{modelid}\" -output_dir ../data/gen2 -prefix llama3d1_8b -n_sample 1 -n_gen 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6234d0-10bf-42ff-ab0d-35f5e60d5104",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modelid=\"unsloth/llama-3-8b-Instruct\"\n",
    "!TRANSFORMERS_OFFLINE=1 python gen_data.py -m gen2   -modelid \"{modelid}\" -output_dir ../data/gen2 -prefix llama3_8b -n_sample 1 -n_gen 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f46f572-ee07-47fd-8a21-e536763de248",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelid=\"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "!TRANSFORMERS_OFFLINE=1 python gen_data.py -m gen2   -modelid \"{modelid}\" -output_dir ../data/gen2 -prefix mistral0d3_7b -n_sample 1 -n_gen 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbe3af6-1b02-4609-b34b-969805ef7640",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelid=\"Qwen/Qwen2-7B-Instruct\"\n",
    "!TRANSFORMERS_OFFLINE=1 python gen_data.py -m gen2   -modelid \"{modelid}\" -output_dir ../data/gen2 -prefix qw2_7b -n_sample 1 -n_gen 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8893c81c-9069-4660-8b04-d6d4c9888a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelid=\"Qwen/Qwen2.5-7B-Instruct\"\n",
    "!TRANSFORMERS_OFFLINE=1 python gen_data.py -m gen2   -modelid \"{modelid}\" -output_dir ../data/gen2 -prefix qw2d5_7b -n_sample 1 -n_gen 6000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b30a109-298d-4f17-b4ba-7e62e943e321",
   "metadata": {},
   "source": [
    "### gen3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5dba36-e2b2-41a2-92c6-440a7f863f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modelid=\"Qwen/Qwen2-7B-Instruct\"\n",
    "!TRANSFORMERS_OFFLINE=1 python gen_data.py -m gen3   -modelid \"{modelid}\" -output_dir ../data/gen3 -prefix qw2_7b -n_sample 1 -temperature 1 -n_gen 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5386599c-0057-4c5b-b13c-117c677a99d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modelid=\"Qwen/Qwen2.5-7B-Instruct\"\n",
    "!TRANSFORMERS_OFFLINE=1 python gen_data.py -m gen3   -modelid \"{modelid}\" -output_dir ../data/gen3 -prefix qw2d5_7b -n_sample 1 -temperature 1 -n_gen 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d066a771-21a8-414f-b94e-54de1669579f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modelid=\"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "!TRANSFORMERS_OFFLINE=1 python gen_data.py -m gen3   -modelid \"{modelid}\" -output_dir ../data/gen3 -prefix mistral0d3_7b -n_sample 1 -temperature 1 -n_gen 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd838175-a0bf-49b3-8e83-1e4d79be2187",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modelid=\"unsloth/llama-3-8b-Instruct\"\n",
    "!TRANSFORMERS_OFFLINE=1 python gen_data.py -m gen3   -modelid \"{modelid}\" -output_dir ../data/gen3 -prefix llama3_8b -n_sample 1 -temperature 1 -n_gen 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c649ef3-3693-40b6-9e75-bc5ae75af0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelid=\"unsloth/Meta-Llama-3.1-8B-Instruct\"\n",
    "!TRANSFORMERS_OFFLINE=1 python gen_data.py -m gen3   -modelid \"{modelid}\" -output_dir ../data/gen3 -prefix llama3d1_8b -n_sample 1 -temperature 1 -n_gen 6000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495504b9-9a2b-49ab-9230-0a0492313458",
   "metadata": {},
   "source": [
    "### gen4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d1aec7-f8a6-4089-9bc2-681d0dec7726",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelid=\"microsoft/Phi-3-small-8k-instruct\"\n",
    "!TRANSFORMERS_OFFLINE=1 python gen_data.py -m gen3   -modelid \"{modelid}\" -output_dir ../data/gen4 -prefix phi3_small -n_sample 1 -temperature 1 -n_gen 6000 -trust_remote_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fd5a5f-622f-4771-8a89-a58e004a9e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modelid=\"01-ai/Yi-1.5-9B-Chat\"\n",
    "!TRANSFORMERS_OFFLINE=1 python gen_data.py -m gen3   -modelid \"{modelid}\" -output_dir ../data/gen4 -prefix yi1d5_9b -n_sample 1 -temperature 1 -n_gen 6000 -trust_remote_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bff5eef-11fa-480a-b89b-b45e03abb0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelid=\"Qwen/Qwen2-7B-Instruct\"\n",
    "!TRANSFORMERS_OFFLINE=1 python gen_data.py -m gen3   -modelid \"{modelid}\" -output_dir ../data/gen4 -prefix qw2_7b -n_sample 1 -temperature 1 -n_gen 6000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0024d089-1b41-49ec-ad4b-2584e75b5956",
   "metadata": {},
   "source": [
    "### gen5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4d6d49-b580-4031-88ba-08b8cf193848",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelid=\"Qwen/Qwen2-7B-Instruct\"\n",
    "!TRANSFORMERS_OFFLINE=1 python gen_data.py -m gen3   -modelid \"{modelid}\" -output_dir ../data/gen5 -prefix qw2_7b -n_sample 1 -temperature 1 -n_gen 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b77562-fb1b-47fa-850a-108a0f6dcf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelid=\"Qwen/Qwen2.5-7B-Instruct\"\n",
    "!TRANSFORMERS_OFFLINE=1 python gen_data.py -m gen3   -modelid \"{modelid}\" -output_dir ../data/gen5 -prefix qw2d5_7b -n_sample 1 -temperature 1 -n_gen 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfe81f3-3926-4fa3-8188-64b8a3e62be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modelid=\"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "!TRANSFORMERS_OFFLINE=1 python gen_data.py -m gen3   -modelid \"{modelid}\" -output_dir ../data/gen5 -prefix mistral0d3_7b -n_sample 1 -temperature 1 -n_gen 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db76a75-81b7-498a-a7bf-ad9c52e56234",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelid=\"unsloth/llama-3-8b-Instruct\"\n",
    "!TRANSFORMERS_OFFLINE=1 python gen_data.py -m gen3   -modelid \"{modelid}\" -output_dir ../data/gen5 -prefix llama3_8b -n_sample 1 -temperature 1 -n_gen 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e681427-9f5b-4a80-a0b7-11c60e7105a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelid=\"unsloth/Meta-Llama-3.1-8B-Instruct\"\n",
    "!TRANSFORMERS_OFFLINE=1 python gen_data.py -m gen3   -modelid \"{modelid}\" -output_dir ../data/gen5 -prefix llama3d1_8b -n_sample 1 -temperature 1 -n_gen 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9542098c-73e8-438a-a6db-3af1d1042f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelid=\"microsoft/Phi-3-small-8k-instruct\"\n",
    "!TRANSFORMERS_OFFLINE=1 python gen_data.py -m gen3   -modelid \"{modelid}\" -output_dir ../data/gen5 -prefix phi3_small -n_sample 1 -temperature 1 -n_gen 30000 -trust_remote_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861f61bd-94b5-4a4b-8c95-8cda5783980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modelid=\"01-ai/Yi-1.5-9B-Chat\"\n",
    "!TRANSFORMERS_OFFLINE=1 python gen_data.py -m gen3   -modelid \"{modelid}\" -output_dir ../data/gen5 -prefix yi1d5_9b -n_sample 1 -temperature 1 -n_gen 30000 -trust_remote_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e646bf-ca16-4380-8d85-ebe7f0ab6ecb",
   "metadata": {},
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b93a709-417c-4c3e-9738-6d82df916cb4",
   "metadata": {},
   "source": [
    "### predict gen3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b295acf-6aa3-4ad5-a490-dbdf5184a69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_names = \"AR_qw2d5_3b_d04\"\n",
    "for model_name in model_names.split():\n",
    "    \n",
    "    !python eval.py  -kn 4 -kfids \"0 1 2 3\" -data_type test  -ds gen3 -vbs 1  -model_name \"{model_name}\" -dataloader_num_workers 4 \\\n",
    "    -torch_dtype float16 -use_fp16 -do_test  -suffix gen3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f1a22f-3745-4cf8-8b24-31f53af658f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = \"AR_gemma2_2b_d02\"\n",
    "for model_name in model_names.split():\n",
    "    \n",
    "    !python eval.py  -kn 4 -kfids \"0 1 2 3\" -data_type test  -ds gen3 -vbs 1  -model_name \"{model_name}\" -dataloader_num_workers 4 \\\n",
    "    -torch_dtype float16 -use_fp16 -do_test  -suffix gen3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d773406-7598-4c23-aa2c-1d93e7f61625",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = \"AR_llama3d2_3b_d03\"\n",
    "for model_name in model_names.split():\n",
    "    \n",
    "    !python eval.py  -kn 4 -kfids \"0 1 2 3\" -data_type test  -ds gen3 -vbs 1  -model_name \"{model_name}\" -dataloader_num_workers 4 \\\n",
    "    -torch_dtype float16 -use_fp16 -do_test  -suffix gen3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1705ea-89bd-4421-8843-8822a0a5e681",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = \"AR_llama3d2_1b_d37\"\n",
    "for model_name in model_names.split():\n",
    "    \n",
    "    !python eval.py  -kn 4 -kfids \"0 1 2 3\" -data_type test  -ds gen3 -vbs 1  -model_name \"{model_name}\" -dataloader_num_workers 4 \\\n",
    "    -torch_dtype float16 -use_fp16 -do_test  -suffix gen3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df0e010-2718-455b-9043-226b44469b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = \"SPLIT_debv2xl_d10 SFT_debv2xl_d120 SFT_debv2xxl_d36\"\n",
    "for model_name in model_names.split():\n",
    "    \n",
    "    !python eval.py  -kn 4 -kfids \"0 1 2 3\" -data_type test  -ds gen3 -vbs 2  -model_name \"{model_name}\" -dataloader_num_workers 4 \\\n",
    "    -torch_dtype float16 -use_fp16 -do_test  -suffix gen3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6802d84-769a-40a5-8339-1ed884737a9a",
   "metadata": {},
   "source": [
    "### predict gen5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47de9bb-ca69-4efe-aa53-3fb4d87c86e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = \"AR_qw2d5_3b_d04\"\n",
    "for model_name in model_names.split():\n",
    "    \n",
    "    !python eval.py  -kn 4 -kfids \"0 1 2 3\" -data_type test  -ds gen5 -vbs 1  -model_name \"{model_name}\" -dataloader_num_workers 4 \\\n",
    "    -torch_dtype float16 -use_fp16 -do_test  -suffix gen5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbdb027-bb49-40d6-9c69-1024fab378db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = \"AR_llama3d2_3b_d03\"\n",
    "for model_name in model_names.split():\n",
    "    \n",
    "    !python eval.py  -kn 4 -kfids \"0 1 2 3\" -data_type test  -ds gen5 -vbs 1  -model_name \"{model_name}\" -dataloader_num_workers 4 \\\n",
    "    -torch_dtype float16 -use_fp16 -do_test  -suffix gen5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796b47f8-c49e-4838-b3ff-ec022d26d866",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = \"AR_llama3d2_1b_d37\"\n",
    "for model_name in model_names.split():\n",
    "    \n",
    "    !python eval.py  -kn 4 -kfids \"0 1 2 3\" -data_type test  -ds gen5 -vbs 1  -model_name \"{model_name}\" -dataloader_num_workers 4 \\\n",
    "    -torch_dtype float16 -use_fp16 -do_test  -suffix gen5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8510d3d9-a59e-4322-95b5-1bb3d163a42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = \"AR_gemma2_2b_d02\"\n",
    "for model_name in model_names.split():\n",
    "    \n",
    "    !python eval.py  -kn 4 -kfids \"0 1 2 3\" -data_type test  -ds gen5 -vbs 1  -model_name \"{model_name}\" -dataloader_num_workers 4 \\\n",
    "    -torch_dtype float16 -use_fp16 -do_test  -suffix gen5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46d075d-2559-4263-8315-1fdfa3d9f29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = \"SPLIT_debv2xl_d10 SFT_debv2xl_d120 SFT_debv2xxl_d36\"\n",
    "for model_name in model_names.split():\n",
    "    \n",
    "    !python eval.py  -kn 4 -kfids \"0 1 2 3\" -data_type test  -ds gen3 -vbs 2  -model_name \"{model_name}\" -dataloader_num_workers 4 \\\n",
    "    -torch_dtype float16 -use_fp16 -do_test  -suffix gen3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c184c07-3f4b-4772-8f90-7a08298d716c",
   "metadata": {},
   "source": [
    "## gen semi label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96b5e94-f908-449b-b1b6-cbd3c8cd0a6a",
   "metadata": {},
   "source": [
    "###  gen3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6c7435-1106-40aa-8618-e283b2fd98eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "DS='gen3'\n",
    "args = util.parser.parse_args([])\n",
    "data = util.load_gen2_data(args, data_dir=DS)\n",
    "model_names = \"SPLIT_debv2xl_d10 SFT_debv2xl_d120 SFT_debv2xxl_d36  AR_gemma2_2b_d02 AR_llama3d2_3b_d03 AR_llama3d2_1b_d37 AR_qw2d5_3b_d04\"\n",
    "step = 0.05\n",
    "#0.8425971893444323\n",
    "model_weights = search_model_weight_func(model_names, step=step)\n",
    "\n",
    "\n",
    "model_names = {model_name:[f\"{model_name}_KF{i}\" for i in range(4)] for model_name in model_names.split()}\n",
    "preds = load_model_preds(model_names, model_weights, suffix=DS)\n",
    "preds = data.merge(preds, on='uid')\n",
    "for i, col in enumerate(util.binary_labels):\n",
    "    preds[col] = preds.pred.apply(lambda x: x[i])\n",
    "preds['InjuryLocationType'] = preds.pred.apply(lambda x: x[len(util.binary_labels):len(util.binary_labels)+util.n_InjuryLocationType])\n",
    "preds['WeaponType1'] =preds.pred.apply(lambda x: x[-util.n_WeaponType1:])\n",
    "preds['src'] = f'semi_{DS}'\n",
    "\n",
    "\n",
    "util.dump(preds, f'../data/semi_{DS}.dump')      \n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fecf9f9-ac26-4985-80af-b52ee468dac9",
   "metadata": {},
   "source": [
    "### gen5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d124ba-9045-4981-b235-5bd5e69e4bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "DS='gen5'\n",
    "args = util.parser.parse_args([])\n",
    "args.dataset = DS\n",
    "data = util.load_data(args)\n",
    "model_names = \"SPLIT_debv2xl_d10 SFT_debv2xl_d120 SFT_debv2xxl_d36  AR_gemma2_2b_d02 AR_llama3d2_3b_d03 AR_llama3d2_1b_d37 AR_qw2d5_3b_d04\"\n",
    "step = 0.05\n",
    "#0.8425971893444323\n",
    "model_weights = search_model_weight_func(model_names, step=step)\n",
    "\n",
    "\n",
    "model_names = {model_name:[f\"{model_name}_KF{i}\" for i in range(4)] for model_name in model_names.split()}\n",
    "preds = load_model_preds(model_names, model_weights, suffix=DS)\n",
    "preds = data.merge(preds, on='uid')\n",
    "for i, col in enumerate(util.binary_labels):\n",
    "    preds[col] = preds.pred.apply(lambda x: x[i])\n",
    "preds['InjuryLocationType'] = preds.pred.apply(lambda x: x[len(util.binary_labels):len(util.binary_labels)+util.n_InjuryLocationType])\n",
    "preds['WeaponType1'] =preds.pred.apply(lambda x: x[-util.n_WeaponType1:])\n",
    "preds['src'] = f'semi_{DS}'\n",
    "\n",
    "\n",
    "util.dump(preds, f'../data/semi_{DS}.dump')      \n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00876917-199f-4aa1-a65c-b68e4415d4c7",
   "metadata": {},
   "source": [
    "# stage 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63841484-a856-4ce8-8942-15f9c27f4bc0",
   "metadata": {},
   "source": [
    "## AR_llama3d2_1b_semid05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c848e01-5e40-46a7-9177-ff8c10fc1b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"AR_llama3d2_1b_semid05\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"unsloth/Llama-3.2-1B-Instruct\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=543509\n",
    "DATASEED=SEED\n",
    "TRAINCOLS=\" \".join(util.all_labels)\n",
    "KN=4\n",
    "KFIDS=\"0\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 0 \\\n",
    "-epochs 2   -max_seq_len 8192  -do_train  -dataloader_num_workers 4 -es 1 -verbose 320 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 2e-4 -warmup_ratio 0.01 -weight_decay 0.01 -bs 1 -gas 32 -vbs 1 -torch_dtype bfloat16 -use_bf16 -train_cols {TRAINCOLS}  \\\n",
    "-use_unsloth -use_lora -lora_dropout 0.05 -lora_alpha 16 -lora_rank 32 -lora_modules q_proj o_proj gate_proj up_proj down_proj k_proj v_proj lm_head  \\\n",
    "-use_ppt2 -aug_order 0.5 -semi_ratio 1 -semi_fpath \"../data/semi_gen3.dump ../data/semi_gen5.dump\" \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 1  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval \\\n",
    "2>&1 | tee -a \"{LOGFILE}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d6a9e6-a6f6-4a94-8a84-83cde631217a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"AR_llama3d2_1b_semid05\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"unsloth/Llama-3.2-1B-Instruct\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=543509\n",
    "DATASEED=SEED\n",
    "TRAINCOLS=\" \".join(util.all_labels)\n",
    "KN=4\n",
    "KFIDS=\"1\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 0 \\\n",
    "-epochs 2   -max_seq_len 8192  -do_train  -dataloader_num_workers 4 -es 1 -verbose 320 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 2e-4 -warmup_ratio 0.01 -weight_decay 0.01 -bs 1 -gas 32 -vbs 1 -torch_dtype bfloat16 -use_bf16 -train_cols {TRAINCOLS}  \\\n",
    "-use_unsloth -use_lora -lora_dropout 0.05 -lora_alpha 16 -lora_rank 32 -lora_modules q_proj o_proj gate_proj up_proj down_proj k_proj v_proj lm_head  \\\n",
    "-use_ppt2 -aug_order 0.5 -semi_ratio 1 -semi_fpath \"../data/semi_gen3.dump ../data/semi_gen5.dump\" \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 1  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval \\\n",
    "2>&1 | tee -a \"{LOGFILE}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c35a6b0-ef3a-4d54-bf9c-ecc07c7de854",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"AR_llama3d2_1b_semid05\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"unsloth/Llama-3.2-1B-Instruct\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=543509\n",
    "DATASEED=SEED\n",
    "TRAINCOLS=\" \".join(util.all_labels)\n",
    "KN=4\n",
    "KFIDS=\"2\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 0 \\\n",
    "-epochs 2   -max_seq_len 8192  -do_train  -dataloader_num_workers 4 -es 1 -verbose 320 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 2e-4 -warmup_ratio 0.01 -weight_decay 0.01 -bs 1 -gas 32 -vbs 1 -torch_dtype bfloat16 -use_bf16 -train_cols {TRAINCOLS}  \\\n",
    "-use_unsloth -use_lora -lora_dropout 0.05 -lora_alpha 16 -lora_rank 32 -lora_modules q_proj o_proj gate_proj up_proj down_proj k_proj v_proj lm_head  \\\n",
    "-use_ppt2 -aug_order 0.5 -semi_ratio 1 -semi_fpath \"../data/semi_gen3.dump ../data/semi_gen5.dump\" \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 1  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval \\\n",
    "2>&1 | tee -a \"{LOGFILE}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ebecda-2f86-48af-a2a3-fa2fb15a9afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"AR_llama3d2_1b_semid05\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"unsloth/Llama-3.2-1B-Instruct\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=543509\n",
    "DATASEED=SEED\n",
    "TRAINCOLS=\" \".join(util.all_labels)\n",
    "KN=4\n",
    "KFIDS=\"3\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 0 \\\n",
    "-epochs 2   -max_seq_len 8192  -do_train  -dataloader_num_workers 4 -es 1 -verbose 320 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 2e-4 -warmup_ratio 0.01 -weight_decay 0.01 -bs 1 -gas 32 -vbs 1 -torch_dtype bfloat16 -use_bf16 -train_cols {TRAINCOLS}  \\\n",
    "-use_unsloth -use_lora -lora_dropout 0.05 -lora_alpha 16 -lora_rank 32 -lora_modules q_proj o_proj gate_proj up_proj down_proj k_proj v_proj lm_head  \\\n",
    "-use_ppt2 -aug_order 0.5 -semi_ratio 1 -semi_fpath \"../data/semi_gen3.dump ../data/semi_gen5.dump\" \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 1  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval \\\n",
    "2>&1 | tee -a \"{LOGFILE}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb56a6e2-4025-4ecd-8742-5e4085d009a8",
   "metadata": {},
   "source": [
    "## AR_llama3d2_3b_semid01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfbde16-9b9f-4507-b8e4-ddde769435ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"AR_llama3d2_3b_semid01\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"unsloth/Llama-3.2-3B-Instruct\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=232567\n",
    "DATASEED=SEED\n",
    "TRAINCOLS=\" \".join(util.all_labels)\n",
    "KN=4\n",
    "KFIDS=\"0\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 0 \\\n",
    "-epochs 2   -max_seq_len 8192  -do_train  -dataloader_num_workers 4 -es 1 -verbose 320 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 2e-4 -warmup_ratio 0.01 -weight_decay 0.01 -bs 1 -gas 32 -vbs 1 -torch_dtype bfloat16 -use_bf16 -train_cols {TRAINCOLS}  \\\n",
    "-use_unsloth -use_lora -lora_dropout 0.05 -lora_alpha 16 -lora_rank 32 -lora_modules q_proj o_proj gate_proj up_proj down_proj k_proj v_proj lm_head  \\\n",
    "-use_ppt2 -aug_order 0.5 -semi_ratio 1 -semi_fpath \"../data/semi_gen3.dump ../data/semi_gen5.dump\"  \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 1  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval \\\n",
    "2>&1 | tee -a \"{LOGFILE}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcf380f-caa1-44ec-872d-a58872b7b595",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"AR_llama3d2_3b_semid01\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"unsloth/Llama-3.2-3B-Instruct\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=232567\n",
    "DATASEED=SEED\n",
    "TRAINCOLS=\" \".join(util.all_labels)\n",
    "KN=4\n",
    "KFIDS=\"1\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 0 \\\n",
    "-epochs 2   -max_seq_len 8192  -do_train  -dataloader_num_workers 4 -es 1 -verbose 320 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 2e-4 -warmup_ratio 0.01 -weight_decay 0.01 -bs 1 -gas 32 -vbs 1 -torch_dtype bfloat16 -use_bf16 -train_cols {TRAINCOLS}  \\\n",
    "-use_unsloth -use_lora -lora_dropout 0.05 -lora_alpha 16 -lora_rank 32 -lora_modules q_proj o_proj gate_proj up_proj down_proj k_proj v_proj lm_head  \\\n",
    "-use_ppt2 -aug_order 0.5 -semi_ratio 1 -semi_fpath \"../data/semi_gen3.dump ../data/semi_gen5.dump\"  \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 1  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval \\\n",
    "2>&1 | tee -a \"{LOGFILE}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a16d61-088c-462e-adda-ba89fbc5c927",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"AR_llama3d2_3b_semid01\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"unsloth/Llama-3.2-3B-Instruct\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=232567\n",
    "DATASEED=SEED\n",
    "TRAINCOLS=\" \".join(util.all_labels)\n",
    "KN=4\n",
    "KFIDS=\"2\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 0 \\\n",
    "-epochs 2   -max_seq_len 8192  -do_train  -dataloader_num_workers 4 -es 1 -verbose 320 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 2e-4 -warmup_ratio 0.01 -weight_decay 0.01 -bs 1 -gas 32 -vbs 1 -torch_dtype bfloat16 -use_bf16 -train_cols {TRAINCOLS}  \\\n",
    "-use_unsloth -use_lora -lora_dropout 0.05 -lora_alpha 16 -lora_rank 32 -lora_modules q_proj o_proj gate_proj up_proj down_proj k_proj v_proj lm_head  \\\n",
    "-use_ppt2 -aug_order 0.5 -semi_ratio 1 -semi_fpath \"../data/semi_gen3.dump ../data/semi_gen5.dump\"  \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 1  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval \\\n",
    "2>&1 | tee -a \"{LOGFILE}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f190e21-ad9a-417e-aa34-61c27cb981a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"AR_llama3d2_3b_semid01\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"unsloth/Llama-3.2-3B-Instruct\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=232567\n",
    "DATASEED=SEED\n",
    "TRAINCOLS=\" \".join(util.all_labels)\n",
    "KN=4\n",
    "KFIDS=\"3\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 0 \\\n",
    "-epochs 2   -max_seq_len 8192  -do_train  -dataloader_num_workers 4 -es 1 -verbose 320 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 2e-4 -warmup_ratio 0.01 -weight_decay 0.01 -bs 1 -gas 32 -vbs 1 -torch_dtype bfloat16 -use_bf16 -train_cols {TRAINCOLS}  \\\n",
    "-use_unsloth -use_lora -lora_dropout 0.05 -lora_alpha 16 -lora_rank 32 -lora_modules q_proj o_proj gate_proj up_proj down_proj k_proj v_proj lm_head  \\\n",
    "-use_ppt2 -aug_order 0.5 -semi_ratio 1 -semi_fpath \"../data/semi_gen3.dump ../data/semi_gen5.dump\"  \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 1  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval \\\n",
    "2>&1 | tee -a \"{LOGFILE}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9502403a-03f2-42c5-8272-f058d355aae6",
   "metadata": {},
   "source": [
    "## AR_gemma2_2b_semid01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecd8209-9ccb-41eb-b9d3-e36e15b13b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"AR_gemma2_2b_semid01\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"unsloth/gemma-2-2b-it\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=905687\n",
    "DATASEED=SEED\n",
    "TRAINCOLS=\" \".join(util.all_labels)\n",
    "KN=4\n",
    "KFIDS=\"0\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 0 \\\n",
    "-epochs 2   -max_seq_len 8192  -do_train  -dataloader_num_workers 4 -es 1 -verbose 320 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 2e-4 -warmup_ratio 0.01 -weight_decay 0.01 -bs 1 -gas 32 -vbs 1 -torch_dtype bfloat16 -use_bf16 -train_cols {TRAINCOLS}  \\\n",
    "-use_unsloth -use_lora -lora_dropout 0.05 -lora_alpha 16 -lora_rank 32 -lora_modules q_proj o_proj gate_proj up_proj down_proj k_proj v_proj lm_head -gradient_checkpointing \\\n",
    "-use_ppt2 -aug_order 0.5 -semi_ratio 1 -semi_fpath \"../data/semi_gen3.dump ../data/semi_gen5.dump\" \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 1  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval \\\n",
    "2>&1 | tee -a \"{LOGFILE}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa22e60-94fb-4dbb-92f0-80376aa0e702",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"AR_gemma2_2b_semid01\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"unsloth/gemma-2-2b-it\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=905687\n",
    "DATASEED=SEED\n",
    "TRAINCOLS=\" \".join(util.all_labels)\n",
    "KN=4\n",
    "KFIDS=\"1\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 0 \\\n",
    "-epochs 2   -max_seq_len 8192  -do_train  -dataloader_num_workers 4 -es 1 -verbose 320 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 2e-4 -warmup_ratio 0.01 -weight_decay 0.01 -bs 1 -gas 32 -vbs 1 -torch_dtype bfloat16 -use_bf16 -train_cols {TRAINCOLS}  \\\n",
    "-use_unsloth -use_lora -lora_dropout 0.05 -lora_alpha 16 -lora_rank 32 -lora_modules q_proj o_proj gate_proj up_proj down_proj k_proj v_proj lm_head -gradient_checkpointing \\\n",
    "-use_ppt2 -aug_order 0.5 -semi_ratio 1 -semi_fpath \"../data/semi_gen3.dump ../data/semi_gen5.dump\" \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 1  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval \\\n",
    "2>&1 | tee -a \"{LOGFILE}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57085a8a-5989-437f-879a-aefa614f6265",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"AR_gemma2_2b_semid01\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"unsloth/gemma-2-2b-it\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=905687\n",
    "DATASEED=SEED\n",
    "TRAINCOLS=\" \".join(util.all_labels)\n",
    "KN=4\n",
    "KFIDS=\"2\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 0 \\\n",
    "-epochs 2   -max_seq_len 8192  -do_train  -dataloader_num_workers 4 -es 1 -verbose 320 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 2e-4 -warmup_ratio 0.01 -weight_decay 0.01 -bs 1 -gas 32 -vbs 1 -torch_dtype bfloat16 -use_bf16 -train_cols {TRAINCOLS}  \\\n",
    "-use_unsloth -use_lora -lora_dropout 0.05 -lora_alpha 16 -lora_rank 32 -lora_modules q_proj o_proj gate_proj up_proj down_proj k_proj v_proj lm_head -gradient_checkpointing \\\n",
    "-use_ppt2 -aug_order 0.5 -semi_ratio 1 -semi_fpath \"../data/semi_gen3.dump ../data/semi_gen5.dump\" \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 1  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval \\\n",
    "2>&1 | tee -a \"{LOGFILE}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b948c807-c6a1-4003-8932-565734decf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"AR_gemma2_2b_semid01\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"unsloth/gemma-2-2b-it\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=905687\n",
    "DATASEED=SEED\n",
    "TRAINCOLS=\" \".join(util.all_labels)\n",
    "KN=4\n",
    "KFIDS=\"3\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 0 \\\n",
    "-epochs 2   -max_seq_len 8192  -do_train  -dataloader_num_workers 4 -es 1 -verbose 320 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 2e-4 -warmup_ratio 0.01 -weight_decay 0.01 -bs 1 -gas 32 -vbs 1 -torch_dtype bfloat16 -use_bf16 -train_cols {TRAINCOLS}  \\\n",
    "-use_unsloth -use_lora -lora_dropout 0.05 -lora_alpha 16 -lora_rank 32 -lora_modules q_proj o_proj gate_proj up_proj down_proj k_proj v_proj lm_head -gradient_checkpointing \\\n",
    "-use_ppt2 -aug_order 0.5 -semi_ratio 1 -semi_fpath \"../data/semi_gen3.dump ../data/semi_gen5.dump\" \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 1  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval \\\n",
    "2>&1 | tee -a \"{LOGFILE}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834a6f33-fe96-48e5-9e51-ae77de6e3ac7",
   "metadata": {},
   "source": [
    "## SFT_debv2xxl_semid03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710099f2-d7e2-4cd0-8a1d-5e1441909db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"SFT_debv2xxl_semid03\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"microsoft/deberta-v2-xxlarge\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=345342\n",
    "DATASEED=SEED\n",
    "KN=4\n",
    "KFIDS=0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids {KFIDS} -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 0 \\\n",
    "-epochs  10  -max_seq_len 8192  -do_train -do_eval -dataloader_num_workers 4 -es 3 -verbose 32 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 5e-5 -warmup_ratio 0.05 -weight_decay 0.01 -bs 1 -gas 64 -vbs 2 -torch_dtype bfloat16 -use_bf16 -is_classify  -use_full -gradient_checkpointing -avg_pool \\\n",
    "-w_bi 0.33333 -w_lt 0.33333 -w_wt 0.33333  -aug_mix 0 -aug_lower 0 -aug_text 0 -bi_rdrop 1 -semi_ratio 1 -semi_fpath \"../data/semi_gen3.dump ../data/semi_gen5.dump\" \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 2  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10b1e79-75db-400a-85ce-3d44ff0c6374",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"SFT_debv2xxl_semid03\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"microsoft/deberta-v2-xxlarge\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=504930\n",
    "DATASEED=345342\n",
    "KN=4\n",
    "KFIDS=\"1\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 0 \\\n",
    "-epochs  10  -max_seq_len 8192  -do_train -do_eval -dataloader_num_workers 4 -es 3 -verbose 32 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 5e-5 -warmup_ratio 0.05 -weight_decay 0.01 -bs 1 -gas 64 -vbs 2 -torch_dtype bfloat16 -use_bf16 -is_classify  -use_full -gradient_checkpointing -avg_pool \\\n",
    "-w_bi 0.33333 -w_lt 0.33333 -w_wt 0.33333  -aug_mix 0 -aug_lower 0 -aug_text 0 -bi_rdrop 1 -semi_ratio 1 -semi_fpath \"../data/semi_gen3.dump ../data/semi_gen5.dump\" \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 2  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a362d5-a504-44e4-a9a1-cbd7c1822180",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"SFT_debv2xxl_semid03\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"microsoft/deberta-v2-xxlarge\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=504930\n",
    "DATASEED=345342\n",
    "KN=4\n",
    "KFIDS=\"2\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 0 \\\n",
    "-epochs  10  -max_seq_len 8192  -do_train -do_eval -dataloader_num_workers 4 -es 3 -verbose 32 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 5e-5 -warmup_ratio 0.05 -weight_decay 0.01 -bs 1 -gas 64 -vbs 2 -torch_dtype bfloat16 -use_bf16 -is_classify  -use_full -gradient_checkpointing -avg_pool \\\n",
    "-w_bi 0.33333 -w_lt 0.33333 -w_wt 0.33333  -aug_mix 0 -aug_lower 0 -aug_text 0 -bi_rdrop 1 -semi_ratio 1 -semi_fpath \"../data/semi_gen3.dump ../data/semi_gen5.dump\" \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 2  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be35c89f-f194-41ab-8e98-e448d2f1c668",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"SFT_debv2xxl_semid03\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"microsoft/deberta-v2-xxlarge\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=546455\n",
    "DATASEED=345342\n",
    "KN=4\n",
    "KFIDS=\"3\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 0 \\\n",
    "-epochs  10  -max_seq_len 8192  -do_train -do_eval -dataloader_num_workers 4 -es 3 -verbose 32 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 5e-5 -warmup_ratio 0.05 -weight_decay 0.01 -bs 1 -gas 64 -vbs 2 -torch_dtype bfloat16 -use_bf16 -is_classify  -use_full -gradient_checkpointing -avg_pool \\\n",
    "-w_bi 0.33333 -w_lt 0.33333 -w_wt 0.33333  -aug_mix 0 -aug_lower 0 -aug_text 0 -bi_rdrop 1 -semi_ratio 1 -semi_fpath \"../data/semi_gen3.dump ../data/semi_gen5.dump\" \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 2  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc885040-e5b6-499d-8680-3bc7e6e33ea4",
   "metadata": {},
   "source": [
    "## SFT_debv2xl_semid11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d695b1-97ae-4e33-b07f-35c2e26a8fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"SFT_debv2xl_semid11\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"microsoft/deberta-v2-xlarge\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=432543\n",
    "DATASEED=19627\n",
    "KN=4\n",
    "KFIDS=\"0\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 2 \\\n",
    "-epochs 10   -max_seq_len 8192  -do_train -do_eval -dataloader_num_workers 4 -es 3 -verbose 32 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 5e-5 -warmup_ratio 0.05 -weight_decay 0.01 -bs 1 -gas 32 -vbs 2 -torch_dtype bfloat16 -use_bf16 -is_classify  -use_full -gradient_checkpointing \\\n",
    "-w_bi 0.33333 -w_lt 0.33333 -w_wt 0.33333  -aug_order 0 -aug_missing 0 -aug_mix 0 -bi_rdrop 1  -avg_pool -semi_ratio 1 -semi_fpath \"../data/semi_gen3.dump ../data/semi_gen5.dump\"  \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 2  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689f826c-1c2f-4601-9c49-40ff48c0730c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"SFT_debv2xl_semid11\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"microsoft/deberta-v2-xlarge\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=432543\n",
    "DATASEED=19627\n",
    "KN=4\n",
    "KFIDS=\"1\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 2 \\\n",
    "-epochs 10   -max_seq_len 8192  -do_train -do_eval -dataloader_num_workers 4 -es 3 -verbose 32 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 5e-5 -warmup_ratio 0.05 -weight_decay 0.01 -bs 1 -gas 32 -vbs 2 -torch_dtype bfloat16 -use_bf16 -is_classify  -use_full -gradient_checkpointing \\\n",
    "-w_bi 0.33333 -w_lt 0.33333 -w_wt 0.33333  -aug_order 0 -aug_missing 0 -aug_mix 0 -bi_rdrop 1  -avg_pool -semi_ratio 1 -semi_fpath \"../data/semi_gen3.dump ../data/semi_gen5.dump\"  \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 2  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab50ad0-a3db-45eb-9c74-3b370521b967",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"SFT_debv2xl_semid11\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"microsoft/deberta-v2-xlarge\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=432543\n",
    "DATASEED=19627\n",
    "KN=4\n",
    "KFIDS=\"2\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 2 \\\n",
    "-epochs 10   -max_seq_len 8192  -do_train -do_eval -dataloader_num_workers 4 -es 3 -verbose 32 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 5e-5 -warmup_ratio 0.05 -weight_decay 0.01 -bs 1 -gas 32 -vbs 2 -torch_dtype bfloat16 -use_bf16 -is_classify  -use_full -gradient_checkpointing \\\n",
    "-w_bi 0.33333 -w_lt 0.33333 -w_wt 0.33333  -aug_order 0 -aug_missing 0 -aug_mix 0 -bi_rdrop 1  -avg_pool -semi_ratio 1 -semi_fpath \"../data/semi_gen3.dump ../data/semi_gen5.dump\"  \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 2  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0911a5-e9de-4c99-9051-2b8983e6aa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"SFT_debv2xl_semid11\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"microsoft/deberta-v2-xlarge\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=343902\n",
    "DATASEED=19627\n",
    "KN=4\n",
    "KFIDS=\"3\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn {KN}  -kfids \"{KFIDS}\" -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 2 \\\n",
    "-epochs 10   -max_seq_len 8192  -do_train -do_eval -dataloader_num_workers 4 -es 3 -verbose 32 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 5e-5 -warmup_ratio 0.05 -weight_decay 0.01 -bs 1 -gas 32 -vbs 2 -torch_dtype bfloat16 -use_bf16 -is_classify  -use_full -gradient_checkpointing \\\n",
    "-w_bi 0.33333 -w_lt 0.33333 -w_wt 0.33333  -aug_order 0 -aug_missing 0 -aug_mix 0 -bi_rdrop 1  -avg_pool -semi_ratio 1 -semi_fpath \"../data/semi_gen3.dump ../data/semi_gen5.dump\"  \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "\n",
    "!python eval.py  -kn {KN} -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 2  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623e4b2d-2d78-4558-8321-2f503ee525cd",
   "metadata": {},
   "source": [
    "## SPLIT_debv2xl_semid06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c4325d-3676-4d5e-877c-f8e7fdbb771f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"SPLIT_debv2xl_semid06\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"microsoft/deberta-v2-xlarge\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=985034\n",
    "DATASEED=SEED\n",
    "KFIDS=0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn 4  -kfids {KFIDS} -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 0 \\\n",
    "-epochs 10   -max_seq_len 8192  -do_train -do_eval -dataloader_num_workers 4 -es 3 -verbose 32 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 5e-5 -warmup_ratio 0.05 -weight_decay 0.01 -bs 1 -gas 32 -vbs 2 -torch_dtype bfloat16 -use_bf16 -is_classify -is_split -use_full -gradient_checkpointing \\\n",
    "-w_bi 0.33333 -w_lt 0.33333 -w_wt 0.33333  -aug_order 0 -aug_missing 0 -aug_mix 0 -aug_text 0 -avg_pool -bi_rdrop 1 -semi_ratio 1 -semi_fpath \"../data/semi_gen3.dump ../data/semi_gen5.dump\" \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn 4 -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 2  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675b00ec-8edb-4384-8f39-70890613c2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"SPLIT_debv2xl_semid06\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"microsoft/deberta-v2-xlarge\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=985034\n",
    "DATASEED=SEED\n",
    "KFIDS=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn 4  -kfids {KFIDS} -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 0 \\\n",
    "-epochs 10   -max_seq_len 8192  -do_train -do_eval -dataloader_num_workers 4 -es 3 -verbose 32 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 5e-5 -warmup_ratio 0.05 -weight_decay 0.01 -bs 1 -gas 32 -vbs 2 -torch_dtype bfloat16 -use_bf16 -is_classify -is_split -use_full -gradient_checkpointing \\\n",
    "-w_bi 0.33333 -w_lt 0.33333 -w_wt 0.33333  -aug_order 0 -aug_missing 0 -aug_mix 0 -aug_text 0 -avg_pool -bi_rdrop 1 -semi_ratio 1 -semi_fpath \"../data/semi_gen3.dump ../data/semi_gen5.dump\" \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn 4 -kfids \"0 1 2 3\" -data_type train  -ds {DS} -vbs 2  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec89473-c58a-4721-ac96-cddb874734e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"SPLIT_debv2xl_semid06\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"microsoft/deberta-v2-xlarge\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=985034\n",
    "DATASEED=SEED\n",
    "KFIDS=\"2\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn 4  -kfids {KFIDS} -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 0 \\\n",
    "-epochs 10   -max_seq_len 8192  -do_train -do_eval -dataloader_num_workers 4 -es 3 -verbose 32 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 5e-5 -warmup_ratio 0.05 -weight_decay 0.01 -bs 2 -gas 16 -vbs 2 -torch_dtype bfloat16 -use_bf16 -is_classify -is_split -use_full -gradient_checkpointing \\\n",
    "-w_bi 0.33333 -w_lt 0.33333 -w_wt 0.33333  -aug_order 0 -aug_missing 0 -aug_mix 0 -aug_text 0 -avg_pool -bi_rdrop 1 -semi_ratio 1 -semi_fpath \"../data/semi_gen3.dump ../data/semi_gen5.dump\" \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn 4 -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 2  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073cadb1-5211-4160-8dc3-892a9145917d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(WORKDIR, PROJECT))\n",
    "\n",
    "import util\n",
    "LOGDIR=f\"{DATADIR}/logs\"\n",
    "!mkdir -p {LOGDIR}\n",
    "LOGFILE=f\"{LOGDIR}/log{util.timestamp()}.log\"\n",
    "print(LOGFILE)\n",
    "\n",
    "\n",
    "MODELNAME=\"SPLIT_debv2xl_semid06\"\n",
    "DS=\"yaa\"\n",
    "DSCLS=\"Dataset\"\n",
    "VDSCLS=\"Dataset\"\n",
    "RESTORE=\"\"\n",
    "BACKBONE=\"microsoft/deberta-v2-xlarge\"\n",
    "# BACKBONE=sorted(glob(f\"../data/{RESTORE}/checkpoint-*))[-1]\n",
    "SEED=985034\n",
    "DATASEED=SEED\n",
    "KFIDS=\"3\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "\n",
    "!python -u sft.py -model_name {MODELNAME} -ds \"{DS}\" -ds_cls \"{DSCLS}\" -val_ds_cls \"{VDSCLS}\" -kn 4  -kfids {KFIDS} -backbone \"{BACKBONE}\" -data_seed {DATASEED} -seed {SEED} -eval_delay 0 \\\n",
    "-epochs 10   -max_seq_len 8192  -do_train -do_eval -dataloader_num_workers 4 -es 3 -verbose 32 -disable_tqdm -save_strategy epoch -evaluation_strategy epoch  -save_total_limit 1 \\\n",
    "-lr 5e-5 -warmup_ratio 0.05 -weight_decay 0.01 -bs 2 -gas 16 -vbs 2 -torch_dtype bfloat16 -use_bf16 -is_classify -is_split -use_full -gradient_checkpointing \\\n",
    "-w_bi 0.33333 -w_lt 0.33333 -w_wt 0.33333  -aug_order 0 -aug_missing 0 -aug_mix 0 -aug_text 0 -avg_pool -bi_rdrop 1 -semi_ratio 1 -semi_fpath \"../data/semi_gen3.dump ../data/semi_gen5.dump\" \\\n",
    "2>&1 | tee \"{LOGFILE}\"\n",
    "\n",
    "!python eval.py  -kn 4 -kfids \"{KFIDS}\" -data_type train  -ds {DS} -vbs 2  -model_name {MODELNAME} -dataloader_num_workers 4 \\\n",
    "-torch_dtype float16 -use_fp16 -do_eval\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
