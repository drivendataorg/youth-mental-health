{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1732005276645
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
        "import torch\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1732005373358
        }
      },
      "outputs": [],
      "source": [
        "agent_model_name = 'google/flan-t5-xl'\n",
        "agent_tokenizer = AutoTokenizer.from_pretrained(agent_model_name)\n",
        "agent_model = T5ForConditionalGeneration.from_pretrained(agent_model_name)\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('mps')\n",
        "agent_model = agent_model.to(device)\n",
        "agent_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1732005379621
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Load JSON from a file\n",
        "with open('../checkpoint/results.json', 'r') as file:\n",
        "    results = json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1732005381135
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "question3 = \"Given a sentence and a relative timing word, transform the timing word into its corresponding numeric value. Return only the number. If no number can be determined, return 'None'.\"\n",
        "\n",
        "question4 = \"\"\"Given a sentence and a relative timing word, select the option that best matches the unit of the timing word. If none of the options are appropriate, choose 'Other':\n",
        "hour or hours\n",
        "minute or minutes\n",
        "day or days\n",
        "month or months\n",
        "week or weeks\n",
        "year or years\n",
        "other\n",
        "\"\"\"\n",
        "\n",
        "question5 = \"Given a sentence and a relative timing expression, identify whether the timing indicates 'before' or 'after' the reference point in the sentence.\"\n",
        "\n",
        "question345 = [question3, question4, question5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1732005386048
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def model_QA(query, question, timing_word):\n",
        "    input_text = f\"\"\"\n",
        "    question: {question}\n",
        "    given sentence: {query}\n",
        "    relative timing word: {timing_word}\n",
        "    answer:\n",
        "    \"\"\"\n",
        "    inputs = agent_tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
        "    output_ids = agent_model.generate(inputs[\"input_ids\"], max_length=500, num_beams=4, early_stopping=True,do_sample=True, temperature = 0.9)\n",
        "    answer = agent_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "    return answer\n",
        "\n",
        "def sequence_QA(query, questions, timing_word):\n",
        "    answers = []\n",
        "    for question in questions:\n",
        "        answer = model_QA(query, question, timing_word)\n",
        "        answers.append(answer)\n",
        "    keys = ['number', 'unit', 'before_or_after']\n",
        "    answer_dict = dict(zip(keys, answers))\n",
        "    return answer_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1732008845636
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "filtered_results = {}\n",
        "\n",
        "for key in tqdm(results):\n",
        "    tmp_timing_words = []\n",
        "    tmp_category_ls = []\n",
        "    tmp_useful_sentences = []\n",
        "    tmp_exact_timing = []\n",
        "\n",
        "    values = results[key]\n",
        "    useful_sentences = values['useful_sentence']\n",
        "    timing_words = values['relative_timing']\n",
        "    category_ls = values['category']\n",
        "    for idx, sentence in enumerate(useful_sentences):\n",
        "        timing_word = timing_words[idx]\n",
        "        query_category = category_ls[idx]\n",
        "        if query_category != 'Other':\n",
        "            tmp_timing_words.append(timing_word)\n",
        "            tmp_category_ls.append(query_category)\n",
        "            tmp_useful_sentences.append(sentence)\n",
        "            answer = sequence_QA(sentence, question345, timing_word)\n",
        "            tmp_exact_timing.append(answer)\n",
        "    if len(tmp_timing_words) != 0:\n",
        "        filtered_results[key] = {\n",
        "            \"useful_sentence\": tmp_useful_sentences,\n",
        "            \"original_timing_word\": tmp_timing_words,\n",
        "            \"category\": tmp_category_ls,\n",
        "            \"exact_timing\": tmp_exact_timing\n",
        "        }        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1732008845927
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "output_file = \"../checkpoint/filtered_results.json\"\n",
        "with open(output_file, \"w\") as json_file:\n",
        "    json.dump(filtered_results, json_file, indent=4)\n",
        "\n",
        "print(f\"Data successfully saved to {output_file}\")"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "ner"
    },
    "kernelspec": {
      "display_name": "Python 3.9 NER",
      "language": "python",
      "name": "ner"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
