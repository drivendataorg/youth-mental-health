{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1731959027882
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1731958921641
        }
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('../input/features_Z140Hep.csv')\n",
        "df['text'] = df['NarrativeLE'] + '.' + df['NarrativeCME']\n",
        "df['text'] = df['text'].str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1731958921745
        }
      },
      "outputs": [],
      "source": [
        "new_df = df[['uid', 'text']]\n",
        "new_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1731958921826
        }
      },
      "outputs": [],
      "source": [
        "# List of keywords\n",
        "keywords = [' second', \n",
        "            ' seconds', \n",
        "            ' second(s)',\n",
        "            ' minute',\n",
        "            ' minutes',\n",
        "            ' minute(s)',\n",
        "            ' min',\n",
        "            ' mins',\n",
        "            ' min(s)',\n",
        "            ' hour',\n",
        "            ' hours',\n",
        "            ' hour(s)',\n",
        "            ' hr',\n",
        "            ' hrs',\n",
        "            ' hr(s)',\n",
        "            ' day',\n",
        "            ' days',\n",
        "            ' week',\n",
        "            ' weeks',\n",
        "            ' week(s)',\n",
        "            ' month',\n",
        "            ' months',\n",
        "            ' month(s)'\n",
        "            ' year',\n",
        "            ' years',\n",
        "            ' year(s)',\n",
        "            'sunday',\n",
        "            'monday',\n",
        "            'tuesday',\n",
        "            'wednesday',\n",
        "            'thursday',\n",
        "            'friday',\n",
        "            'saturday',\n",
        "            'morning',\n",
        "            'afternoon',\n",
        "            'evening'\n",
        "            ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1731958922128
        }
      },
      "outputs": [],
      "source": [
        "# Filter rows where any keyword exists in the text\n",
        "new_df = new_df[new_df['text'].str.contains('|'.join(keywords), case=False, na=False)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1731958922471
        }
      },
      "outputs": [],
      "source": [
        "new_df['matched_keywords'] = new_df['text'].apply(lambda x: ', '.join([kw for kw in keywords if kw in x.lower()]))\n",
        "new_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1731959491308
        }
      },
      "outputs": [],
      "source": [
        "agent_model_name = 'google/flan-t5-xl'\n",
        "agent_tokenizer = AutoTokenizer.from_pretrained(agent_model_name)\n",
        "agent_model = T5ForConditionalGeneration.from_pretrained(agent_model_name)\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('mps')\n",
        "agent_model = agent_model.to(device)\n",
        "agent_model.eval()\n",
        "\n",
        "def model_QA(query, question):\n",
        "    input_text = f\"\"\"\n",
        "    question: {question}\n",
        "    given sentence: {query}\n",
        "    answer:\n",
        "    \"\"\"\n",
        "    inputs = agent_tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
        "    output_ids = agent_model.generate(inputs[\"input_ids\"], max_length=500, num_beams=4, early_stopping=True,do_sample=True, temperature = 0.9)\n",
        "    answer = agent_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1731959494863
        }
      },
      "outputs": [],
      "source": [
        "question = \"\"\"\n",
        "Given the sentence, check if it contains a relative timing reference.\n",
        "If it does, return the exact wording from the given sentence. Otherwise, return 'None'.\n",
        "\"\"\"\n",
        "questions = [question]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1731959496326
        }
      },
      "outputs": [],
      "source": [
        "uuid_ls = new_df['uid'].tolist()\n",
        "text_ls = new_df['text'].tolist()\n",
        "keyword_ls = new_df['matched_keywords'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1731959497439
        }
      },
      "outputs": [],
      "source": [
        "def split_sentence(paragraph):\n",
        "    sentences = nltk.sent_tokenize(paragraph)\n",
        "    return sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1731959056570
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1731959123662
        }
      },
      "outputs": [],
      "source": [
        "results = {}\n",
        "\n",
        "for idx, paragraph in enumerate(tqdm(text_ls)):\n",
        "    useful_sentence = []\n",
        "    relative_timing = []\n",
        "    uuid = uuid_ls[idx]\n",
        "    keyword_matched = keyword_ls[idx]\n",
        "    sentences = split_sentence(paragraph)\n",
        "    for sentence in sentences:\n",
        "        answer = model_QA(sentence, questions)\n",
        "        if answer != 'None':\n",
        "            useful_sentence.append(sentence)\n",
        "            relative_timing.append(answer)\n",
        "\n",
        "    results[uuid] = {\n",
        "        \"useful_sentence\": useful_sentence,\n",
        "        \"relative_timing\": relative_timing,\n",
        "        \"keyword_matched\": keyword_matched\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1731970608637
        }
      },
      "outputs": [],
      "source": [
        "question2 = \"\"\"\n",
        "Given the following sentence, choose the option that best describes its content.\n",
        "If no option seems appropriate, select 'Other':\n",
        "\n",
        "Argument with family : The victim had an argument or conflict with family member\n",
        "Depressed mood or mental health : The victim was depressed or had a mental health condition\n",
        "Drug : The victim took drugs\n",
        "Alcohol : The victim drank alcohol\n",
        "Weapon: The victim got, bought or purchased a weapon\n",
        "Relationship problem with partner : The victim had relationship Problem with a partner, such as break up, divorce\n",
        "Love message:  The victim sent or spoke \"I love you\" related messages to someone\n",
        "School problem : The victim had problems at or related to school\n",
        "Job problem : The victim had job problems, such as losting jobs, cannot get a job\n",
        "Financial problem : The victim had financial problems\n",
        "Death of friend or family : A family member or friend of the victim died\n",
        "History of suicide attempt: The victim attempted to suicide before, such as cutting their wrists, overdosing on pills, or hanging themselves.\n",
        "Thought of suicide: The victim thought or plan to suicide before.\n",
        "Death of victim : The victim died, such as cutting their wrists, overdosing on pills, hanging, or shot themselves\n",
        "Other: other\n",
        "\"\"\"\n",
        "question2 = [question2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1731975385548
        }
      },
      "outputs": [],
      "source": [
        "for key in tqdm(results):\n",
        "    values = results[key]\n",
        "    useful_sentences = values['useful_sentence']\n",
        "    category = []\n",
        "    for sentence in useful_sentences:\n",
        "        answer = model_QA(sentence, question2)\n",
        "        category.append(answer)\n",
        "    values['category'] = category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1731975385734
        }
      },
      "outputs": [],
      "source": [
        "import json \n",
        "\n",
        "# Save to a JSON file\n",
        "output_file = \"../checkpoint/results.json\"\n",
        "with open(output_file, \"w\") as json_file:\n",
        "    json.dump(results, json_file, indent=4)\n",
        "\n",
        "print(f\"Data successfully saved to {output_file}\")"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "ner"
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
