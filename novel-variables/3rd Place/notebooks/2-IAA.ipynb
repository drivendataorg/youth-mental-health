{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import krippendorff\n",
    "import itertools\n",
    "\n",
    "# change for feedback\n",
    "VERBOSE = True\n",
    "DEBUG = False\n",
    "SELECT_CODES = [\"Relevance\", \"1\", \"2\", \"5\", \"3\", \"4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = pd.read_csv('../data/external/final-annotations.csv')\n",
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_20 = pd.read_csv('../data/external/initial-20.csv')\n",
    "initial_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_20['For IAA'] = 1\n",
    "initial_20['initial-20'] = 1\n",
    "annotations = annotations.rename(columns={'Relevant?': 'Relevance'})\n",
    "annotations = pd.concat([annotations, initial_20])\n",
    "annotations = annotations[['For IAA', 'uid', 'Person', 'Certain Codes', 'Uncertain Codes', 'Relevance']]\n",
    "annotations['For IAA'] = annotations['For IAA'].fillna(0)\n",
    "missing_relevance = annotations[annotations['Relevance'].isna()]\n",
    "\n",
    "if VERBOSE:\n",
    "  print(f\"There are {missing_relevance.shape[0]} assignments with missing relevance values.\")\n",
    "\n",
    "annotations = annotations.dropna(subset='Relevance')\n",
    "num_cases = annotations[\"uid\"].nunique()\n",
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Certain Codes', 'Uncertain Codes']:\n",
    "  annotations[col] = annotations[col].apply(lambda x: set(code.strip(\n",
    "  ) for code in str(x).replace('.', '').split(',')) if not pd.isna(x) else set())\n",
    "\n",
    "annotations['codes'] = annotations.apply(lambda row: set.union(\n",
    "  row['Certain Codes'], row['Uncertain Codes']), axis=1)\n",
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_unique_codes = list(set.union(*annotations['codes']))\n",
    "all_unique_codes.sort()\n",
    "for code in all_unique_codes:\n",
    "  annotations[code] = annotations['codes'].apply(\n",
    "    lambda x: 1 if code in x else 0)\n",
    "\n",
    "annotations.to_csv('../data/interim/annotations.csv', index=False)\n",
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_codes_per_annotator = annotations.drop(columns=['uid', 'Certain Codes', 'Uncertain Codes', 'codes', 'Relevance']).groupby('Person').sum()\n",
    "total_codes_per_annotator.to_csv('../data/interim/annotator-codes.csv')\n",
    "total_codes_per_annotator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coded_disclosure = annotations[(\n",
    "  (annotations['0'] == 1) | (annotations['01'] == 1))]\n",
    "nvdrs = pd.read_csv(\"../data/raw/nvdrs-youth-restricted.csv\")[\n",
    "    ['uid', 'DisclosedToSocialMedia']]\n",
    "coded_disclosure = coded_disclosure.merge(\n",
    "  nvdrs[['uid', 'DisclosedToSocialMedia']], on='uid', how='left')\n",
    "count_coded_disclosure = coded_disclosure.shape[0]\n",
    "count_provided_dislosure = coded_disclosure['DisclosedToSocialMedia'].sum()\n",
    "proportion_agreement = count_provided_dislosure / count_coded_disclosure\n",
    "\n",
    "if VERBOSE:\n",
    "  print(f\"{count_coded_disclosure} cases were coded for disclosure (0 or 0.1) by at least one person.\")\n",
    "  print(f\"From these cases, {int(count_provided_dislosure)} were marked for 'DisclosedToSocialMedia'.\")\n",
    "  print(f\"{(1 - proportion_agreement) * 100}% of cases that we found to include social media disclosure were not marked for 'DisclosedToSocialMedia'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_codes = pd.DataFrame(columns=['Code', \"Krippendorff's Alpha\"])\n",
    "\n",
    "for code in SELECT_CODES:\n",
    "  reliability_data = annotations[['Person', 'uid', code]][annotations['For IAA'] == 1].drop_duplicates(\n",
    "    subset=['Person', 'uid']).pivot(index='Person', columns='uid', values=code)\n",
    "  reliability_data_input = [[value for value in row]\n",
    "                            for row in reliability_data.values]\n",
    "\n",
    "  if annotations[annotations['For IAA'] == 1][code].sum() != 0:\n",
    "    alpha = krippendorff.alpha(\n",
    "      reliability_data=reliability_data_input, level_of_measurement='nominal')\n",
    "  else:\n",
    "    if VERBOSE:\n",
    "      print(\n",
    "        f\"Code {code} does not have enough data to calculate Krippendorff's Alpha.\")\n",
    "    alpha = pd.NA\n",
    "\n",
    "  unique_codes = unique_codes._append(\n",
    "    {'Code': code, \"Krippendorff's Alpha\": alpha}, ignore_index=True)\n",
    "\n",
    "unique_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_agreements(case: pd.DataFrame, code: str, majority: bool = False):\n",
    "  case = case.reset_index(drop=True)\n",
    "  agreed = 0\n",
    "  disagreed = 0\n",
    "  count_true = case[code].sum()\n",
    "  count_false = case.shape[0] - count_true\n",
    "\n",
    "  if DEBUG:\n",
    "    print()\n",
    "    print(case)\n",
    "\n",
    "  combinations = list(itertools.combinations(list(range(case.shape[0])), 2))\n",
    "\n",
    "  if DEBUG:\n",
    "    print(\"Combinations: \", combinations)\n",
    "\n",
    "  for combination in combinations:\n",
    "    val1 = case.iloc[combination[0]][code]\n",
    "    person1 = case.iloc[combination[0]]['Person']\n",
    "    val2 = case.iloc[combination[1]][code]\n",
    "    person2 = case.iloc[combination[1]]['Person']\n",
    "    if val1 == val2:\n",
    "      if DEBUG:\n",
    "        print(f\"{person1} agrees with {person2} ({val1},{val2})\")\n",
    "      agreed += 1\n",
    "    else:\n",
    "      if DEBUG:\n",
    "        print(f\"{person1} disagrees with {person2} ({val1},{val2})\")\n",
    "      disagreed += 1\n",
    "\n",
    "  if majority:\n",
    "    if count_true == count_false:\n",
    "      return 0\n",
    "    elif count_true > count_false:\n",
    "      return 1\n",
    "    else:\n",
    "      return -1\n",
    "\n",
    "  return agreed, disagreed\n",
    "\n",
    "\n",
    "def prop_pairwise_agreement(annotations: pd.DataFrame, code: str):\n",
    "  agreed = 0\n",
    "  disagreed = 0\n",
    "  IAA_annotations = annotations[annotations['For IAA'] == 1]\n",
    "  cases = IAA_annotations[['uid', 'Person', code]]\n",
    "\n",
    "  if cases[code].sum() == 0:\n",
    "    return pd.NA\n",
    "\n",
    "  cases = cases.groupby('uid')\n",
    "\n",
    "  for case in cases:\n",
    "    case_agreed, case_disagreed = count_agreements(case[1], code)\n",
    "\n",
    "    if DEBUG:\n",
    "      print(f\"For code {code}, case {case[0]} has {case_agreed} agreements and {case_disagreed} disagreements.\")\n",
    "\n",
    "    agreed += case_agreed\n",
    "    disagreed += case_disagreed\n",
    "\n",
    "  if VERBOSE:\n",
    "    print(f\"Code {code} has {agreed} agreements and {disagreed} disagreements.\")\n",
    "\n",
    "  return agreed / (agreed + disagreed)\n",
    "\n",
    "\n",
    "tied_cases = list(list())\n",
    "\n",
    "unique_codes['Pairwise Agreement'] = unique_codes['Code'].apply(\n",
    "  lambda code: prop_pairwise_agreement(annotations, code))\n",
    "# unique_codes['Count'] = unique_codes['Code'].apply(\n",
    "  # lambda code: annotations[code].sum())\n",
    "\n",
    "if VERBOSE:\n",
    "  print(\"Number of cases that were annotated:\", num_cases)\n",
    "\n",
    "# unique_codes['Prevalence'] = unique_codes['Count'] / num_cases\n",
    "unique_codes.to_csv(\"../data/processed/codes.csv\", index=False)\n",
    "unique_codes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
